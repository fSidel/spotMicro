<launch>
    <!-- 
        Arguments to launch camera without loading a model or 
        to launch a debug window to see the boundaries detection 
        -->
    <arg name="no_model" default="false"/> 
    <arg name="boundaries_debug" default="false"/>  
    

    <!-- 
        Launch camera publisher node 
    -->
    <node pkg="spot_micro_perception" 
    type="cameraPublisher.py" 
    name="camera_publisher_node" 
    output="screen"/>


    <!-- 
        When no_model:=true launch camera subscriber node without object detection 
    -->
    <group if="$(arg no_model)">
        <node pkg="spot_micro_perception" 
        type="cameraSubscriber.py" 
        name="camera_subscriber_node" 
        output="screen"/>
    </group>


    <!-- 
        When no_model:=false the system needs a model for object detection, we specify a default but
        another alternative may be provided with: 

        weights:= name_of_weights, 
        cfg:= name_of_cfg, 
        labels:= name_of_labels, 
        width:= input_width_of_model,
        height:= input_height_of_model,

        Note! For  weights and cfg the launch files expects the files to be in the folder:
        ..../spot_micro_perception/configs/networks/
        While the labels are expected to be in 
        ..../spot_micro_perception/configs/labels/
     -->
    <group unless="$(arg no_model)">
        <arg name="weights" default="yolov2.weights"/>
        <arg name="cfg" default="yolov2.cfg"/>  
        <arg name="labels" default="coco.txt"/>
        <arg name="width" default="416"/>
        <arg name="height" default="416"/>
        
        <!-- 
            Launches the object detection manager node, this node  tries
            to recognize the architecture of the model and load it with the 
            appropriate tools. As of now only Darknet is supported but after
            refactoring to ROS Humble support will be improved.
        -->
        <node pkg="spot_micro_perception" 
        type="spotMicroDetectionManager.py" 
        name="detection_publisher" 
        output="screen">
            <param name="model_weights" value="$(find spot_micro_perception)/configs/networks/$(arg weights)"/>
            <param name="model_cfg" value="$(find spot_micro_perception)/configs/networks/$(arg cfg)"/>
            <param name="model_labels" value="$(find spot_micro_perception)/configs/labels/$(arg labels)"/>
            <param name="model_width" value="$(arg width)"/>
            <param name="model_height" value="$(arg height)"/>
        </node>
     
        <!-- 
            Launches the object detection debugger node. This greatly
            degrades performance so only launch this when checking if the model
            is working properly.
        -->
        <group if="$(arg boundaries_debug)">
            <node pkg="spot_micro_perception" 
            type="opencvDetectionDebug.py" 
            name="detection_debug" 
            output="screen"/>
        </group>

    </group>
</launch>
